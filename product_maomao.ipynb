{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cUsqF5l8zuXC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU, Conv2DTranspose, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# 设置参数\n",
        "img_rows, img_cols, channels = 28, 28, 1  # 图像尺寸和通道数\n",
        "noise_dim = 100  # 噪声向量维度\n",
        "batch_size = 64\n",
        "epochs = 12000\n",
        "sample_interval = 500  # 保存模型生成图像的频率\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义生成器\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128 * 7 * 7, activation='relu', input_dim=noise_dim))\n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same', activation='relu'))\n",
        "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "    model.add(Conv2DTranspose(channels, kernel_size=3, strides=2, padding='same', activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# 定义判别器\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(img_rows, img_cols, channels)))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Fkuk3lpX2hum"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 构建生成器和判别器\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "# 编译判别器\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
        "\n",
        "# 构建整体模型\n",
        "z = Input(shape=(noise_dim,))\n",
        "img = generator(z)\n",
        "discriminator.trainable = False\n",
        "real_or_fake = discriminator(img)\n",
        "combined = Model(z, real_or_fake)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n"
      ],
      "metadata": {
        "id": "Euo9r_qK2jrH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_quickdraw_data():\n",
        "    import urllib.request\n",
        "    import json\n",
        "\n",
        "    url = \"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\"\n",
        "    urllib.request.urlretrieve(url, 'cat.npy')\n",
        "    cats = np.load('cat.npy')\n",
        "\n",
        "    # 数据预处理\n",
        "    cats = cats.reshape(-1, img_rows, img_cols, channels)\n",
        "    cats = cats.astype('float32') / 255\n",
        "    return cats\n",
        "\n",
        "cats = load_quickdraw_data()\n"
      ],
      "metadata": {
        "id": "Ur1qLQ2r2lrf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # 训练判别器\n",
        "        idx = np.random.randint(0, cats.shape[0], batch_size)\n",
        "        real_imgs = cats[idx]\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_imgs, valid)\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # 训练生成器\n",
        "        noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "        g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "        # 打印进度和保存样本\n",
        "        if epoch % sample_interval == 0:\n",
        "            print(\"Epoch: %d, D loss: %f, G loss: %f\" % (epoch, d_loss[0], g_loss))\n",
        "            sample_images(epoch)\n"
      ],
      "metadata": {
        "id": "7A11Xy5H2qpJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_images(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, noise_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"cat_%d.png\" % epoch)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "-Le5F7ta2sTB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()\n"
      ],
      "metadata": {
        "id": "0mPdrJOh2uoz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}